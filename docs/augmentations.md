# Augmentations

Data augmentation is an effective way to improve the performance of deep networks by exposing the models to more data variety. Many methods currently available are developed for high-level vision tasks (e.g., classification) and fewer are dedicated to low-level vision tasks (e.g., image restoration), specially under a GAN training formulation. The methods discarding or manipulating the pixels or features too much can potentially hamper the image restoration, where the spatial relationship is very important. In this repository there are three types of augmentations that can be used for different purposes according to the task at hand:
- Per [image augmentation](https://github.com/victorca25/traiNNer/wiki/Dataset-Augmentation) are single image augmentations that can be used to change (transform) the image distribution: add noise, blur, downscale interpolation method, etc. The augmentations are implemented in [augmennt](https://github.com/victorca25/augmennt/), ['/codes/dataops/imresize.py'](https://github.com/victorca25/traiNNer/blob/master/codes/dataops/imresize.py) and ['/codes/dataops/augmentations.py'](https://github.com/victorca25/traiNNer/blob/master/codes/dataops/augmentations.py)
- [Batch augmentations](https://arxiv.org/pdf/2004.00448.pdf) (cutmix, mixup, blend, rgb, cutout, cutblur) is a series of augmentations that are applied to entire mini batches of images, some of which combine random regions from images inside the batch to other images in the batch. This mixture of augmentations (MoA) can help regularize the models to learn to identify locality to where and when transformations are applied. The batch augmentations are implemented in ['/codes/dataops/batchaug.py'](https://github.com/victorca25/traiNNer/blob/master/codes/dataops/batchaug.py)
- [Differential augmentations](https://arxiv.org/pdf/2006.10738.pdf). Unlike the previous two augmentation types, which alter the images statistics and altering the data the Generator networks observe (potentially introducing distortions and color shifts), DiffAugment are augmentations for the Discriminator of a GAN formulation. These augmentations are applied to both `real` and `fake` (generated) images and can be backpropagated to the generator, promoting Discriminators that do not memorize the exact training data and must learn to extract better details from the images. In effect, this allows to train GAN models with a fraction of the images of the typical case (even down to 10%), with limited impact on the results. The differential augmentations are implemented in ['/codes/dataops/diffaug.py'](https://github.com/victorca25/traiNNer/blob/master/codes/dataops/diffaug.py)
      

# Downscaling methods and augmentation pipeline

It is important to note that in many cases the original trained models made available from research papers usually fail to produce good results with images from the wild (ie. the internet) and the reason is these networks are typically trained under specific conditions that can be evaluated and compared with previous research.

They generally assume the relationship between high resolution (`HR`) images and their low resolution (`LR`) pair is that of  an ideal `bicubic` kernel. The networks learn to revert this specific transformation, but most natural images have not been downscaled previously with a `bicubic` kernel and the models fail to produce adequate results during inference with new images after the they have been trained. This is why using custom trained models from the [model database](https://upscale.wiki/wiki/Model_Database) can produce better results than most official models for their particular use case.

For this purpose, one of the first additions of this repository was to include additional downscaling methods (based on OpenCV: `nearest`, `bilinear`, `bicubic`, `lanczos`, in addition to the Matlab-like imresize `antialiased bicubic`) that are applied on the fly, randomized if multiple of them are selected in the training options. Besides the downscaling method, an [augmentation](#augmentations) pipeline that includes applying random noises, compression and blur was also added to better approximate real world degradation in images. Due to the increased number and complexity of the image augmentation pipeline, these were outsourced to the [augmennt](https://github.com/victorca25/augmennt/) repository, while the number of interpolation methods [available](https://github.com/victorca25/traiNNer/blob/master/codes/dataops/imresize.py) was substantially increased and now includes antialiased versions of: `blackman5`, `blackman4`, `blackman3`, `blackman2`, `sinc5`, `sinc4`, `sinc3`, `sinc2`, `gaussian`, `hamming`, `hanning`, `catrom`, `bell`, `hermite`, `mitchell`, `cubic` (bicubic), `lanczos5`, `lanczos4`, `lanczos3`, `lanczos2`, `box`, `linear` (bilinear). Lastly, a new [algorithm](https://github.com/assafshocher/ResizeRight) that solves typical downscaling [issues](https://github.com/GaParmar/clean-fid) present in most frameworks used to train machine learning models (OpenCV, PIL, Tensorflow, PyTorch, etc) was also adopted for the antialiased downscaling.

Later, papers like [KSMR](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Kernel_Modeling_Super-Resolution_on_Real_Low-Resolution_Images_ICCV_2019_paper.pdf) (2019) and [Real-SR](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Ji_Real-World_Super-Resolution_via_Kernel_Estimation_and_Noise_Injection_CVPRW_2020_paper.pdf) (2020) introduced the idea of using realistic kernels estimated from images (for example, using [KernelGAN](https://arxiv.org/pdf/1909.06581.pdf)) and using this pool of extracted kernels to downscale `HR` images and generate the `LR` pairs. While the process of extracting the kernels has to be done offline (follow the instructions in [DLIP](https://github.com/victorca25/DLIP/)), using this repository it is also possible to [apply](https://github.com/victorca25/traiNNer/blob/master/docs/kernels.md) the kernels for realistically downscaling `HR` images to generate the `LR` on the fly, as part of the randomized methods. In addition, `Real-SR` also used a previous idea of adding realistic noise extracted from [images patches](https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Image_Blind_Denoising_CVPR_2018_paper.pdf), which can be injected to the downscaled images that lose the natural noise properties in the downscaling process (follow the instructions in [DLIP](https://github.com/victorca25/DLIP/)). These extracted natural noise patches can also be added to images on the fly. Using `DLIP` it will be possible to apply these (and other) methods offline before training if preferred at a later time.

More recently (2021), in addition to the randomized downscaling, noise
and blur pipeline, [BSRGAN](https://arxiv.org/pdf/2103.14006v1.pdf)
introduced the idea of using anisotropic gaussian blur kernels, "down
an up" image scaling, processed camera sensor noise (from
reverse-forward camera image signal processing ISP pipeline model)
and RAW image noise model to add more diversity to the degradation
pipeline. These ideas are pending to be added, but will be available
at a later point in time in this repository.

Both `Real-SR` and `BSRGAN` use the `ESRGAN` network with no change other
than the images used to train the network, demonstrating there's still
plenty of room for improvement based solely on the datasets used. Note
that the strategies used in both cases can be applied simultaneously
in this repository (with some augmentations pending).

An additional strategy to be tested is using a network trained to
generate the `LR` images like [DSGAN](https://github.com/ManuelFritsche/real-world-sr).
